import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd
import re
from nltk.stem import SnowballStemmer

# --- ConfiguraciÃ³n de la PÃ¡gina ---
st.set_page_config(page_title="Demo TF-IDF EspaÃ±ol", layout="wide", initial_sidebar_state="collapsed")

# --- Estilos CSS Personalizados ---
st.markdown("""
<style>
    /* Color de fondo de la app */
    .stApp {
        background-color: #f0f2f6;
    }
    
    /* Contenedor principal para centrar y aÃ±adir padding */
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
        padding-left: 2rem;
        padding-right: 2rem;
    }

    /* Estilo de "Tarjeta" para las columnas de entrada */
    [data-testid="column"] {
        background-color: #ffffff;
        border-radius: 12px;
        padding: 25px !important; /* !important para sobreescribir padding */
        box-shadow: 0 6px 20px rgba(0,0,0,0.04);
        border: 1px solid #e6e6e6;
        transition: all 0.3s ease;
    }
    
    [data-testid="column"]:hover {
         box-shadow: 0 8px 25px rgba(0,0,0,0.06);
    }

    /* Espacio entre las tarjetas de columna */
    [data-testid="column"]:first-child {
        margin-right: 15px;
    }
    [data-testid="column"]:last-child {
        margin-left: 15px;
    }

    /* Botones de sugerencias (secundarios) */
    .stButton > button {
        border-radius: 8px;
        border: 1px solid #d0d0d0;
        background-color: #fafafa;
        color: #333;
    }
    .stButton > button:hover {
        background-color: #f0f0f0;
        border-color: #c0c0c0;
        color: #000;
    }
    
    /* BotÃ³n primario de "Analizar" */
    .stButton > button[kind="primary"] {
        background-color: #0072c6; /* Azul */
        border: none;
        border-radius: 8px;
        font-weight: 600;
    }
    .stButton > button[kind="primary"]:hover {
        background-color: #0056b3;
    }

    /* Estilo para la respuesta 'success' */
    .stSuccess {
        background-color: #e6f7ff;
        border: 1px solid #b3e0ff;
        border-radius: 8px;
        color: #0056b3;
        font-size: 1.05rem;
    }
    
    /* TÃ­tulos */
    h1 {
        color: #1a1a1a;
        font-weight: 600;
    }
    h3 {
        color: #333;
        border-bottom: 2px solid #f0f2f6;
        padding-bottom: 5px;
    }
</style>
""", unsafe_allow_html=True)

# --- TÃ­tulo y DescripciÃ³n ---
st.title("ğŸ” Demo de BÃºsqueda SemÃ¡ntica (TF-IDF) en EspaÃ±ol")
st.write("""
Esta aplicaciÃ³n utiliza TF-IDF y la similitud del coseno para encontrar el documento mÃ¡s relevante para tu pregunta.
El anÃ¡lisis incluye *stemming* en espaÃ±ol (ej: "jugar", "jugando", "juegan" se tratan como "jug").
""")

# --- Documentos de Ejemplo ---
default_docs = """El perro ladra fuerte en el parque.
El gato maÃºlla suavemente durante la noche.
El perro y el gato juegan juntos en el jardÃ­n.
Los niÃ±os corren y se divierten en el parque.
La mÃºsica suena muy alta en la fiesta.
Los pÃ¡jaros cantan hermosas melodÃ­as al amanecer."""

# --- Funciones de Procesamiento ---
# Stemmer en espaÃ±ol
stemmer = SnowballStemmer("spanish")

def tokenize_and_stem(text):
    # MinÃºsculas
    text = text.lower()
    # Solo letras espaÃ±olas y espacios
    text = re.sub(r'[^a-zÃ¡Ã©Ã­Ã³ÃºÃ¼Ã±\s]', ' ', text)
    # Tokenizar
    tokens = [t for t in text.split() if len(t) > 1]
    # Aplicar stemming
    stems = [stemmer.stem(t) for t in tokens]
    return stems

# --- LÃ³gica de Estado para Sugerencias ---

# Inicializar estado de sesiÃ³n para la pregunta
if 'question' not in st.session_state:
    st.session_state.question = "Â¿DÃ³nde juegan el perro y el gato?"

# FunciÃ³n callback para actualizar la pregunta
def set_question(q_text):
    st.session_state.question = q_text

# --- Layout de la Interfaz ---
st.header("1. Ingresa tus Datos")

# Usamos un contenedor para aplicar el fondo de tarjeta
with st.container():
    col1, col2 = st.columns([2, 1])

    with col1:
        text_input = st.text_area("ğŸ“ Documentos (uno por lÃ­nea):", default_docs, height=210)
        
        # El 'key' "question" vincula este input a st.session_state.question
        question = st.text_input("â“ Escribe tu pregunta:", key="question")

    with col2:
        st.markdown("### ğŸ’¡ Preguntas sugeridas:")
        
        st.button(
            "Â¿DÃ³nde juegan el perro y el gato?", 
            on_click=set_question, 
            args=["Â¿DÃ³nde juegan el perro y el gato?"], 
            use_container_width=True
        )
        st.button(
            "Â¿QuÃ© hacen los niÃ±os en el parque?", 
            on_click=set_question, 
            args=["Â¿QuÃ© hacen los niÃ±os en el parque?"], 
            use_container_width=True
        )
        st.button(
            "Â¿CuÃ¡ndo cantan los pÃ¡jaros?", 
            on_click=set_question, 
            args=["Â¿CuÃ¡ndo cantan los pÃ¡jaros?"], 
            use_container_width=True
        )
        st.button(
            "Â¿DÃ³nde suena la mÃºsica alta?", 
            on_click=set_question, 
            args=["Â¿DÃ³nde suena la mÃºsica alta?"], 
            use_container_width=True
        )
        st.button(
            "Â¿QuÃ© animal maÃºlla durante la noche?", 
            on_click=set_question, 
            args=["Â¿QuÃ© animal maÃºlla durante la noche?"], 
            use_container_width=True
        )


st.write("---") # Separador

# --- LÃ³gica de AnÃ¡lisis y Resultados ---
if st.button("ğŸ” Analizar y Encontrar Respuesta", type="primary", use_container_width=True):
    
    # Usar la pregunta de st.session_state
    current_question = st.session_state.question
    documents = [d.strip() for d in text_input.split("\n") if d.strip()]
    
    if len(documents) < 1:
        st.error("âš ï¸ Ingresa al menos un documento.")
    elif not current_question.strip():
        st.error("âš ï¸ Escribe una pregunta.")
    else:
        try:
            st.header("2. Resultados del AnÃ¡lisis")
            
            # Crear vectorizador TF-IDF
            vectorizer = TfidfVectorizer(
                tokenizer=tokenize_and_stem,
                min_df=1  # Incluir todas las palabras
            )
            
            # Ajustar con documentos
            X = vectorizer.fit_transform(documents)
            
            # Calcular similitud con la pregunta
            question_vec = vectorizer.transform([current_question])
            similarities = cosine_similarity(question_vec, X).flatten()
            
            # Encontrar mejor respuesta
            best_idx = similarities.argmax()
            best_doc = documents[best_idx]
            best_score = similarities[best_idx]
            
            # --- Mostrar Respuesta Principal ---
            st.markdown("### ğŸ¯ Respuesta MÃ¡s Relevante")
            st.markdown(f"**Tu pregunta:** *{current_question}*")
            
            if best_score > 0.01:  # Umbral
                st.success(f"**Mejor coincidencia (Documento {best_idx+1}):**\n\n>{best_doc}")
                st.write(f"**Puntaje de similitud:** {best_score:.3f}")
                
                # Mostrar stems coincidentes
                vocab = vectorizer.get_feature_names_out()
                q_stems = tokenize_and_stem(current_question)
                matched = [s for s in q_stems if s in vocab and X[best_idx].toarray()[0][vectorizer.vocabulary_[s]] > 0]
                st.write("**Stems coincidentes:**", f"`{', '.join(matched) or 'Ninguno'}`")
                
            else:
                st.warning(f"No se encontrÃ³ una buena coincidencia (puntaje mÃ¡s alto: {best_score:.3f}).")

            
            st.write("---") # Separador

            # --- Detalles Adicionales en Expanders ---
            st.markdown("### ğŸ”¬ Detalles del AnÃ¡lisis")

            with st.expander("Ver todos los puntajes de similitud"):
                sim_df = pd.DataFrame({
                    "Documento": [f"Doc {i+1}" for i in range(len(documents))],
                    "Texto": documents,
                    "Similitud": similarities
                })
                st.dataframe(sim_df.sort_values("Similitud", ascending=False), use_container_width=True)

            with st.expander("Ver Matriz TF-IDF (stems)"):
                df_tfidf = pd.DataFrame(
                    X.toarray(),
                    columns=vectorizer.get_feature_names_out(),
                    index=[f"Doc {i+1}" for i in range(len(documents))]
                )
                st.dataframe(df_tfidf.round(3), use_container_width=True)

        except ValueError as e:
            if "empty vocabulary" in str(e):
                st.error("âš ï¸ Error: No se pudo construir un vocabulario. AsegÃºrate de que los documentos no estÃ©n vacÃ­os o compuestos solo de 'stop words' (palabras comunes).")
            else:
                st.error(f"OcurriÃ³ un error: {e}")
        except Exception as e:
            st.error(f"OcurriÃ³ un error inesperado: {e}")
